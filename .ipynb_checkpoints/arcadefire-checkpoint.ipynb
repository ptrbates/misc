{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arcade Fire is cool! What are their songs about?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import os.path\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here are the urls for the song list\n",
    "url_list = [\"https://azlyrics.org/artist/NwB0qP6z.html\", \"https://azlyrics.org/artist/NwB0qP6z.html?p=2\", \\\n",
    "            \"https://azlyrics.org/artist/NwB0qP6z.html?p=3\", \"https://azlyrics.org/artist/NwB0qP6z.html?p=4\"]\n",
    "\n",
    "# Save the html from those pages\n",
    "r = [requests.get(url) for url in url_list]\n",
    "html = [page.text for page in r]\n",
    "\n",
    "# Soup up the html\n",
    "soups = [BeautifulSoup(page, 'html.parser') for page in html]\n",
    "\n",
    "# Find the links in each page\n",
    "links = []\n",
    "for soup in soups:\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the song lyric urls from the links; make them direct links\n",
    "pattern = re.compile(\"https://azlyrics.org/lyrics/\")\n",
    "songs = []\n",
    "\n",
    "for link in links:\n",
    "    try:\n",
    "        if bool(pattern.match(link)):\n",
    "            songs.append(link)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "songs = sorted(list(set(songs)))\n",
    "len(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 61 songs on the list. azlyrics.com has 92, so I guess we could check to see if that's a good number? Someday. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a function to get the lyrics for a song on the list\n",
    "def get_lyrics(link):\n",
    "    \n",
    "    # Get the page, and split out the lyrics\n",
    "    r = requests.get(link)\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    text = soup.find('div', attrs={'class': '_lyricItem'}).text\n",
    "    lyrics = text.split('\\n\\r\\n')[1].split('Songwriters')[0]\n",
    "    title = text.split('\\n\\r\\n')[0].split('to \"')[1].split('\" song')[0]\n",
    "    \n",
    "    # Remove some of the tags and such...\n",
    "    lyrics = re.sub(r\"'\", '', lyrics)\n",
    "    lyrics = re.sub(r'\\n|\\r|<i>|</i>|<br/>|</div>|\\[\\w+\\]|\\[\\w+ \\w+\\]|\\(|\\)|\\.', ' ', lyrics)\n",
    "    lyrics = re.sub(r'\\s+|\\W+', ' ', lyrics)\n",
    "    \n",
    "    # Tokenize the results\n",
    "    text_tokens = re.split(r\"\\s+\", lyrics)\n",
    "\n",
    "    # Split the words that are strung together due to lack of line breaks...\n",
    "    lyrics = []\n",
    "    for lyric in text_tokens:\n",
    "        if re.match(r\"^[a-z]+[A-Z]\", lyric):\n",
    "            lyrics.append(re.split(r\"[A-Z]\", lyric)[0])\n",
    "            lyrics.append(re.split(r\"^[a-z]+\", lyric)[1])\n",
    "        else:\n",
    "            lyrics.append(lyric)            \n",
    "\n",
    "    # Convert to lowercase:\n",
    "    lyrics = [t.lower() for t in lyrics]\n",
    "\n",
    "    return(title, lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see whether afsongs.p already exists\n",
    "\n",
    "if os.path.exists('afsongs.p'):\n",
    "    # If it does, go ahead and load it into song_dict\n",
    "    with open('afsongs.p', 'rb') as f:\n",
    "        song_dict = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "    # If it doesn't, build a dictionary of all the songs and dump it to the file for next time\n",
    "    song_dict = {}\n",
    "    \n",
    "    for i in range(len(songs)):\n",
    "        time.sleep(1)\n",
    "        response = get_lyrics(songs[i])\n",
    "        song_dict[response[0]] = response[1]\n",
    "    \n",
    "    with open('afsongs.p', 'wb') as f:\n",
    "        pickle.dump(song_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out the stopwords\n",
    "ns_songs = {}\n",
    "\n",
    "for song in song_dict.keys():\n",
    "    ns_songs[song] = [w for w in song_dict[song] if w not in stopwords.words('english')]\n",
    "    \n",
    "# Create a corpus using the songs\n",
    "dictionary = Dictionary(ns_songs.values())\n",
    "corpus = [dictionary.doc2bow(doc) for doc in ns_songs.values()]\n",
    "\n",
    "# Create a Tf-idf model of corpus\n",
    "tfidf = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23, 0.05204451068891513),\n",
       " (78, 0.21979702878986218),\n",
       " (79, 0.33163204085716025),\n",
       " (80, 0.33163204085716025),\n",
       " (81, 0.4916385682686395),\n",
       " (82, 0.16387952275621318),\n",
       " (83, 0.16387952275621318),\n",
       " (84, 0.16387952275621318),\n",
       " (85, 0.16387952275621318),\n",
       " (86, 0.4916385682686395),\n",
       " (87, 0.10796201672256414),\n",
       " (88, 0.16387952275621318),\n",
       " (89, 0.13818925244901295),\n",
       " (90, 0.16387952275621318),\n",
       " (91, 0.16387952275621318),\n",
       " (92, 0.16387952275621318)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[corpus[1]]\n",
    "corpus.ge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
